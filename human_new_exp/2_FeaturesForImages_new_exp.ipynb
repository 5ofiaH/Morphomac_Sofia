{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction - new_exp_human \n",
    "#### 2024-20-12 \n",
    "#### new macrophage human data\n",
    "#### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP: Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSCanonical, PLSRegression, CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "import matplotlib  as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "%matplotlib inline\n",
    "import os, shutil, glob\n",
    "from PIL import Image\n",
    "from itertools import cycle\n",
    "from random import randint\n",
    "import re, math\n",
    "import seaborn as sns; sns.set_style(\"white\")\n",
    "from sklearn.manifold import TSNE\n",
    "import datetime\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modify!!! CHECK WORKING-DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: /home/jovyan/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/plot\n",
      "Output folder for plots: /home/jovyan/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/plot\n",
      "Output folder for aggregated results: /home/jovyan/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/plot\n",
      "Aggregate function: <function nanmean at 0x7e70dc14a0e0>\n",
      "Plate name prefix: ImageMeanPlate\n"
     ]
    }
   ],
   "source": [
    "# Set current working directory\n",
    "\n",
    "def setup_directories(plate_id, dataset_name, output_dir, aggregate_function, plate_name_prefix):\n",
    "    # Define paths\n",
    "    PathToPlots = f'/home/jovyan/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/{dataset_name}'\n",
    "    PathToOut = f'/home/jovyan/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/{dataset_name}'\n",
    "    \n",
    "    # Check and create PathToPlots if it doesn't exist\n",
    "    if not os.path.exists(PathToPlots):\n",
    "        os.makedirs(PathToPlots)\n",
    "        print(f\"Created directory: {PathToPlots}\")\n",
    "    print(f\"Output folder for plots: {PathToPlots}\")\n",
    "    \n",
    "    # Check and create PathToOut if it doesn't exist\n",
    "    if not os.path.exists(PathToOut):\n",
    "        os.makedirs(PathToOut)\n",
    "        print(f\"Created directory: {PathToOut}\")\n",
    "    print(f\"Output folder for aggregated results: {PathToOut}\")\n",
    "    \n",
    "    # Set additional parameters\n",
    "    print(f\"Aggregate function: {aggregate_function}\")\n",
    "    print(f\"Plate name prefix: {plate_name_prefix}\")\n",
    "\n",
    "    return PathToOut, PathToPlots\n",
    "# Example usage\n",
    "plate_id = '24025'  # Modify this value to change the plate\n",
    "dataset_name = 'plot'\n",
    "output_dir = 'ImageMeanFeatures'\n",
    "aggregate_function = np.nanmean\n",
    "plate_name_prefix = 'ImageMeanPlate'\n",
    "selected_analysis_id = 8336\n",
    "PathToOut, PathToPlots = setup_directories(plate_id, dataset_name, output_dir, aggregate_function, plate_name_prefix)\n",
    "\n",
    "# Now you can proceed with your data processing, assuming that the directories exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More setup\n",
    "import sqlalchemy\n",
    "\n",
    "# settings to display more columns and rows\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "\n",
    "# Connection info for the database\n",
    "db_uri = 'postgresql://pharmbio_readonly:readonly@imagedb-pg-postgresql.services.svc.cluster.local/imagedb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160621-Wash-Optimisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020_11_04_CPJUMP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24OHC-v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A549-VictorChildIMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agi-test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    project\n",
       "0  160621-Wash-Optimisation\n",
       "1        2020_11_04_CPJUMP1\n",
       "2                  24OHC-v1\n",
       "3       A549-VictorChildIMX\n",
       "4                  agi-test"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# List projects that have analyses results\n",
    "#\n",
    "query = \"\"\"\n",
    "        SELECT project\n",
    "        FROM image_analyses_per_plate\n",
    "        GROUP BY project\n",
    "        ORDER BY project \n",
    "        \"\"\"\n",
    "\n",
    "# Query database and store result in pandas dataframe\n",
    "df_projects = pd.read_sql_query(query, db_uri)\n",
    "\n",
    "display(df_projects.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>plate_barcode</th>\n",
       "      <th>plate_acq_name</th>\n",
       "      <th>plate_acq_id</th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>analysis_date</th>\n",
       "      <th>analysis_error</th>\n",
       "      <th>meta</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>results</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morphomac</td>\n",
       "      <td>2024-W50-Macrophages</td>\n",
       "      <td>2024-W50-Macrophages</td>\n",
       "      <td>5499</td>\n",
       "      <td>8335</td>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>None</td>\n",
       "      <td>{'type': 'cp-features', 'priority': None, 'standard_pipeline': True}</td>\n",
       "      <td>csv384-96_HMPSC_FEAT_ICFImg_Cellpose_v2_n50_c150_ft0.8</td>\n",
       "      <td>/share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8335/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morphomac</td>\n",
       "      <td>2024-W50-Macrophages</td>\n",
       "      <td>2024-W50-Macrophages</td>\n",
       "      <td>5499</td>\n",
       "      <td>8336</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>None</td>\n",
       "      <td>{'type': 'cp-features', 'priority': None, 'standard_pipeline': True}</td>\n",
       "      <td>csv384-96_HMPSC_FEAT_ICFImg_Cellpose_v2_HCT116_P53mut</td>\n",
       "      <td>/share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8336/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     project         plate_barcode        plate_acq_name  plate_acq_id  \\\n",
       "0  Morphomac  2024-W50-Macrophages  2024-W50-Macrophages          5499   \n",
       "1  Morphomac  2024-W50-Macrophages  2024-W50-Macrophages          5499   \n",
       "\n",
       "   analysis_id analysis_date analysis_error  \\\n",
       "0         8335    2024-12-19           None   \n",
       "1         8336    2024-12-20           None   \n",
       "\n",
       "                                                                   meta  \\\n",
       "0  {'type': 'cp-features', 'priority': None, 'standard_pipeline': True}   \n",
       "1  {'type': 'cp-features', 'priority': None, 'standard_pipeline': True}   \n",
       "\n",
       "                                            pipeline_name  \\\n",
       "0  csv384-96_HMPSC_FEAT_ICFImg_Cellpose_v2_n50_c150_ft0.8   \n",
       "1   csv384-96_HMPSC_FEAT_ICFImg_Cellpose_v2_HCT116_P53mut   \n",
       "\n",
       "                                                                       results  \\\n",
       "0  /share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8335/   \n",
       "1  /share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8336/   \n",
       "\n",
       "  dataset_name  \n",
       "0         None  \n",
       "1         None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# List analyses for specified project\n",
    "#\n",
    "# type could be 'cp-features' OR 'cp-qc'\n",
    "#\n",
    "NameContains = '2024-W50-Macrophages'\n",
    "query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM image_analyses_per_plate\n",
    "        WHERE plate_barcode LIKE '{NameContains}%%'\n",
    "        AND meta->>'type' = 'cp-features'\n",
    "        AND analysis_date IS NOT NULL\n",
    "        ORDER BY plate_acq_id, analysis_id\n",
    "        \"\"\"\n",
    "\n",
    "# Query database and store result in pandas dataframe\n",
    "df_cp_results = pd.read_sql_query(query, db_uri)\n",
    "\n",
    "display(df_cp_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Duplicate results found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plate_acq_id</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5499</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   plate_acq_id  size\n",
       "0          5499     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Warn if duplicate results\n",
    "df_with_count = df_cp_results.groupby(df_cp_results.plate_acq_id.tolist(),as_index=False).size()\n",
    "df_dupes = df_with_count[df_with_count['size'] > 1]\n",
    "\n",
    "if(df_dupes.empty):\n",
    "    print(\"OK, no duplicate results found\")\n",
    "else:\n",
    "     print(\"WARNING! Duplicate results found\")\n",
    "     display(df_dupes.rename(columns={'index':'plate_acq_id'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify!! select analysis_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>plate_barcode</th>\n",
       "      <th>plate_acq_name</th>\n",
       "      <th>plate_acq_id</th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>analysis_date</th>\n",
       "      <th>analysis_error</th>\n",
       "      <th>meta</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>results</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morphomac</td>\n",
       "      <td>2024-W50-Macrophages</td>\n",
       "      <td>2024-W50-Macrophages</td>\n",
       "      <td>5499</td>\n",
       "      <td>8336</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>None</td>\n",
       "      <td>{'type': 'cp-features', 'priority': None, 'standard_pipeline': True}</td>\n",
       "      <td>csv384-96_HMPSC_FEAT_ICFImg_Cellpose_v2_HCT116_P53mut</td>\n",
       "      <td>/share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8336/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     project         plate_barcode        plate_acq_name  plate_acq_id  \\\n",
       "1  Morphomac  2024-W50-Macrophages  2024-W50-Macrophages          5499   \n",
       "\n",
       "   analysis_id analysis_date analysis_error  \\\n",
       "1         8336    2024-12-20           None   \n",
       "\n",
       "                                                                   meta  \\\n",
       "1  {'type': 'cp-features', 'priority': None, 'standard_pipeline': True}   \n",
       "\n",
       "                                           pipeline_name  \\\n",
       "1  csv384-96_HMPSC_FEAT_ICFImg_Cellpose_v2_HCT116_P53mut   \n",
       "\n",
       "                                                                       results  \\\n",
       "1  /share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8336/   \n",
       "\n",
       "  dataset_name  \n",
       "1         None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select rows where analysis_id is ---\n",
    "df_cp_results = df_cp_results[df_cp_results['analysis_id'] == selected_analysis_id]\n",
    "\n",
    "display(df_cp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing selected plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2024-W50-Macrophages\n",
       "Name: plate_acq_name, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cp_results.plate_acq_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify! Output directory Alternate between Mean and Median by uncommenting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/data/analyses/sofia/morphomac/Morphomac_Sofia/human_new_exp\n",
      "/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/plot\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('/home/jovyan/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/plot/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify!! Means or Medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time : \n",
      "2024-12-20 22:55:32\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print ('Current date and time : ')\n",
    "print (now.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double check the OutputDir!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2024-12-20 22:55:39\n",
      "for plate: 1 of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'featICF_nuclei'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start reading File /share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8336/featICF_nuclei.parquet\n",
      "2024-12-20 22:55:39\n",
      "Done reading File /share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8336/featICF_nuclei.parquet\n",
      "2024-12-20 22:55:45\n",
      "Dataframe contains 734 columns and 395794 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'featICF_cells'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start reading File /share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8336/featICF_cells.parquet\n",
      "2024-12-20 22:55:45\n",
      "Done reading File /share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8336/featICF_cells.parquet\n",
      "2024-12-20 22:55:51\n",
      "Dataframe contains 735 columns and 360308 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'featICF_cytoplasm'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start reading File /share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8336/featICF_cytoplasm.parquet\n",
      "2024-12-20 22:55:51\n",
      "Done reading File /share/data/cellprofiler/automation/results/2024-W50-Macrophages/5499/8336/featICF_cytoplasm.parquet\n",
      "2024-12-20 22:55:57\n",
      "Dataframe contains 726 columns and 360307 rows.\n",
      "Merge nuclei and cells dataframes\n",
      "2024-12-20 22:55:57\n",
      "(395794, 1469)\n",
      "Merge cytoplasm dataframe\n",
      "2024-12-20 22:55:58\n",
      "(395794, 2195)\n",
      "(395794, 2195)\n",
      "Input: 2024-W50-Macrophages\n",
      "Output: /home/jovyan/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/plot\n",
      "Dataset shape: (395794, 2195)\n",
      "before Wells2024-12-20 22:56:00\n",
      "2024-12-20 22:56:00\n",
      "C D E F G H I J K L M N\n",
      "03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22\n",
      "Number of sites: 9\n",
      "Number of wells: 240 (full plate is 240)\n",
      "2024-12-20 22:56:00\n",
      "before grouped by image2024-12-20 22:56:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_92979/3196916635.py:130: FutureWarning: The provided callable <function nanmean at 0x7e70dc14a0e0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  groupedbyImage = df.groupby(['ImageID','Metadata_Barcode','Metadata_Well', 'Metadata_Site','Metadata_AcqID'], as_index=False).agg(dictOfnumericColsAggregationFunctions)\n",
      "/tmp/ipykernel_92979/3196916635.py:130: FutureWarning: The provided callable <function nanmean at 0x7e70dc14a0e0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  groupedbyImage = df.groupby(['ImageID','Metadata_Barcode','Metadata_Well', 'Metadata_Site','Metadata_AcqID'], as_index=False).agg(dictOfnumericColsAggregationFunctions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before save to parquet2024-12-20 22:56:08\n",
      "done save to parquet2024-12-20 22:56:09\n",
      "read file: /home/jovyan/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/plot/ImageMeanPlate_2024-W50-Macrophages.parquet\n",
      "Start save /home/jovyan/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/plot/ImageMeanPlateAllPlates.parquet\n",
      "Done save file /home/jovyan/share/data/analyses/sofia/morphomac/human_new_exp_files/features_output/plot/ImageMeanPlateAllPlates.parquet\n"
     ]
    }
   ],
   "source": [
    "skip_existing = False\n",
    "\n",
    "# Double chek the Outputdir\n",
    "OutputDir = f\"{PathToOut}\"\n",
    "aggregateFunction = np.nanmean\n",
    "plateNamePrefix = 'ImageMeanPlate'\n",
    "\n",
    "if not os.path.exists(OutputDir): \n",
    "    os.makedirs(OutputDir)\n",
    "\n",
    "# Processing each plate\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "print ('Start: ' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "for index, oneplate_analysis_meta in df_cp_results.iterrows():\n",
    "    \n",
    "    print (f'for plate: {index} of { len(df_cp_results.index) }')\n",
    "    \n",
    "    #display(oneplate_analysis_meta)\n",
    "    \n",
    "    one_plate_filename = f'{ OutputDir }/{plateNamePrefix}_{ oneplate_analysis_meta[\"plate_acq_name\"] }.parquet'\n",
    "    \n",
    "    if os.path.exists(one_plate_filename) and skip_existing:\n",
    "        print(f'File exist already, skipping this plate: {one_plate_filename}')\n",
    "        continue\n",
    "\n",
    "    # Data Processing: reading and merging of features files for each plate (NUCLEI, CELLS, CYTOPLASM)\n",
    "    DataFrameDictionary = {}\n",
    "    featureFileNames = ['featICF_nuclei', 'featICF_cells', 'featICF_cytoplasm']\n",
    "    for featName in featureFileNames:\n",
    "        display(featName)\n",
    "\n",
    "        DataFrameDictionary[featName] = pd.DataFrame()\n",
    "        ReadingFile = 0\n",
    "\n",
    "        DataFromFolder =  pd.DataFrame()\n",
    "\n",
    "        file = oneplate_analysis_meta['results'] + featName + '.parquet'\n",
    "\n",
    "        print(f'Start reading File {file}') \n",
    "        print (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        DataFromOneFile =  pd.read_parquet(file) # OBS!!! nrows is just for debugging/development\n",
    "        print(f'Done reading File {file}') \n",
    "        print (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "        #display(DataFromOneFile.head(1000))\n",
    "        \n",
    "        DataFrameDictionary[featName] = DataFromOneFile\n",
    "\n",
    "        # Add ( _nuclei, _cells, _cytoplasm suffix to column names\n",
    "        DataFrameDictionary[featName].columns = [str(col) + '_' + re.sub('_.*', '', re.sub('featICF_', '', featName)) for col in DataFrameDictionary[featName]]\n",
    "\n",
    "        print ('Dataframe contains {} columns and {} rows.'.format(DataFrameDictionary[featName].shape[1],\n",
    "                                                              DataFrameDictionary[featName].shape[0]))\n",
    "\n",
    "\n",
    "    # Merges nuclei, cells, and cytoplasm data into a single dataframe\n",
    "    print(f'Merge nuclei and cells dataframes')\n",
    "    print (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    df = DataFrameDictionary['featICF_nuclei'].merge(DataFrameDictionary['featICF_cells'], left_on = [ 'Metadata_Barcode_nuclei',\n",
    "    'Metadata_Site_nuclei', 'Metadata_Well_nuclei','Parent_cells_nuclei'],\n",
    "                       right_on = [ 'Metadata_Barcode_cells',\n",
    "    'Metadata_Site_cells', 'Metadata_Well_cells','ObjectNumber_cells'], how='left')\n",
    "    print(df.shape)\n",
    "\n",
    "    print(f'Merge cytoplasm dataframe')\n",
    "    print (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    df = df.merge(DataFrameDictionary['featICF_cytoplasm'], left_on = [ 'Metadata_Barcode_nuclei',\n",
    "    'Metadata_Site_nuclei', 'Metadata_Well_nuclei','Parent_cells_nuclei'],\n",
    "                       right_on = [ 'Metadata_Barcode_cytoplasm',\n",
    "    'Metadata_Site_cytoplasm', 'Metadata_Well_cytoplasm','ObjectNumber_cytoplasm'], how='left')\n",
    "    print(df.shape)\n",
    "    # df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(df.shape)\n",
    "    print('Input: {}'.format(NameContains))\n",
    "    print('Output: {}'.format(OutputDir))\n",
    "    print('Dataset shape: {}'.format(df.shape))\n",
    "\n",
    "    del DataFrameDictionary\n",
    "    gc.collect()\n",
    "\n",
    "    NrOfObjects = df.shape[0]\n",
    "    print ('before Wells' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    Wells = sorted(list(set(df['Metadata_Well_nuclei'])))\n",
    "    print (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    NrOfWells = len(Wells)\n",
    "    Rows = sorted(list(set([w[0] for w in Wells])))\n",
    "    print(*Rows)\n",
    "    NrOfRows = len(Rows)\n",
    "    Columns = sorted(list(set([w[1:] for w in Wells])))\n",
    "    NrOfColumns = len(Columns)\n",
    "    print(*Columns)\n",
    "    Sites = sorted(list(set(df['Metadata_Site_nuclei'])))\n",
    "    NrOfSites = len(Sites)\n",
    "    # print('Plate complete: {}'.format(NrOfRows*NrOfColumns==NrOfWells))\n",
    "    print('Number of sites: {}'.format(NrOfSites))\n",
    "    AllWells =[]\n",
    "    for R in Rows:\n",
    "        for C in Columns:\n",
    "            RC = R + C\n",
    "            # print(RC)\n",
    "            AllWells += [RC]\n",
    "    # print(len(AllWells))\n",
    "    print('Number of wells: {} (full plate is {})'.format(NrOfWells, len(AllWells)))\n",
    "    \n",
    "    #\n",
    "    # Add and update column (as a workaround It should be included in cellprofiler result in future)\n",
    "    #\n",
    "    df['Metadata_AcqID_nuclei'] = oneplate_analysis_meta['plate_acq_id']\n",
    "    df['Metadata_Barcode_nuclei'] = oneplate_analysis_meta['plate_barcode']\n",
    "    \n",
    "\n",
    "    # Rename some columns\n",
    "    df.rename(columns = {'Metadata_Barcode_nuclei':'Metadata_Barcode',\n",
    "                         'Metadata_Well_nuclei':'Metadata_Well',\n",
    "                         'Metadata_Site_nuclei':'Metadata_Site',\n",
    "                         'Metadata_AcqID_nuclei':'Metadata_AcqID'}, inplace = True)\n",
    "    \n",
    "    # Create an ImageId column by merging <Barcode>_<Well>_<Site>\n",
    "    df['ImageID'] =  df['Metadata_AcqID'].astype(str) + '_' + df['Metadata_Barcode'] + '_' + df['Metadata_Well'] + '_' + df['Metadata_Site'].astype(str)\n",
    "    print (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    df.select_dtypes(include=np.number) \n",
    "\n",
    "    numeric_columns = df.select_dtypes(include=np.number).columns.tolist()#\n",
    "\n",
    "    dictOfnumericColsAggregationFunctions = { i : aggregateFunction for i in numeric_columns}\n",
    "\n",
    "    print ('before grouped by image' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    groupedbyImage = df.groupby(['ImageID','Metadata_Barcode','Metadata_Well', 'Metadata_Site','Metadata_AcqID'], as_index=False).agg(dictOfnumericColsAggregationFunctions)\n",
    "    # remove this when running on single cell. groupedbyImage \n",
    "    print ('before save to parquet' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    groupedbyImage.to_parquet( one_plate_filename )\n",
    "    print ('done save to parquet' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    del groupedbyImage\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "# Now finally read all one-plate files and concat them into an AllPlates-file\n",
    "groupedbyImageAllPlates = pd.DataFrame()\n",
    "for index, oneplate_analysis_meta in df_cp_results.iterrows(): \n",
    "    one_plate_filename = f'{ OutputDir }/{plateNamePrefix}_{ oneplate_analysis_meta[\"plate_acq_name\"] }.parquet'\n",
    "    print(f'read file: {one_plate_filename}')\n",
    "    df = pd.read_parquet(one_plate_filename)\n",
    "    groupedbyImageAllPlates = pd.concat([groupedbyImageAllPlates, df])\n",
    "    \n",
    "all_plates_outfile = f'{OutputDir}/{plateNamePrefix}AllPlates.parquet'\n",
    "print(f'Start save {all_plates_outfile}')\n",
    "groupedbyImageAllPlates.to_parquet(all_plates_outfile)\n",
    "print(f'Done save file {all_plates_outfile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time : \n",
      "2024-12-20 22:56:26\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print ('Current date and time : ')\n",
    "print (now.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
